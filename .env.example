# ============================================
# LLM Provider Configuration
# ============================================
# LLM_PROVIDER=gemini  # Options: gemini, openai, kimi

# Google API Configuration (Legacy)
# Used for: LLM (Gemini), Memory Embeddings, and Fact Extraction
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-pro

# Kimi (Moonshot AI) Configuration
KIMI_API_KEY=your_kimi_api_key_here
# KIMI_MODEL=moonshot-v1-8k

# OpenAI API Configuration (Recommended)
# Used for: LLM (GPT-4o Mini), Memory Embeddings (text-embedding-3-small)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# LLM Configuration (applies to both providers)
TEMPERATURE=0.7
EMBEDDING_MODEL=text-embedding-3-small

# System Prompt (optional)
SYSTEM_PROMPT=You are a helpful AI assistant. Provide clear, accurate, and concise responses.

# Feature Flags
USE_LANGGRAPH=false  # Set to 'true' to use new LangGraph agent (requires OpenAI)

# Memory Configuration
# See config/memory.yaml for detailed memory settings
MEMORY_ENABLED=true

# Neo4j Configuration (for memory graph database)
NEO4J_URL=neo4j://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password123

# Logging Configuration
LOG_LEVEL=INFO

# Frontend Configuration (for Next.js)
PYTHON_BACKEND_URL=http://localhost:8000
